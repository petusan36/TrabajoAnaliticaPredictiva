{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo Analítica predictiva\n",
    "====\n",
    "---\n",
    "<h3>Pedro Turriago Sanchez</h3>\n",
    "**pturriago@unal.edu.co**   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia  \n",
    "Url github: https://github.com/petusan36/TrabajoAnaliticaPredictiva/blob/master/DataBankMarketingDataSet-AnalysisPython.ipynb\n",
    "DataSet: bank_af.csv\n",
    "Ruta DataSet github: https://github.com/petusan36/TrabajoAnaliticaPredictiva/blob/master/bank_af.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Contenido\n",
    "== \n",
    "- <h2> Definición del problema real </h2>\n",
    "    - <h3>Objetivo</h3>\n",
    "- <h2>Información de atributos </h2>\n",
    "    - <h3> Variables de entrada </h3>\n",
    "        - <h4> Datos del cliente</h4>\n",
    "    - <h3> Importación de las librerias </h3>\n",
    "    - <h3> Definición de funciones </h3>\n",
    "    - <h3> Importación de los datos </h3>\n",
    "- <h2> Fase de exploración y limpieza de la información </h2>\n",
    "    - <h3> Análisis exploratorio Nro 1 </h3>\n",
    "        - <h4> Modelamiento Nro 1 </h4>\n",
    "            - <h5> Linear Regresion (Regesión lineal / regresión logística)</h5>\n",
    "                - Entrenamiento\n",
    "                - Prueba\n",
    "                - Matriz de confusión\n",
    "        - <h4> Primeras conclusiones </h4>\n",
    "    - <h3> Análisis exploratorio Nro 2 </h3>\n",
    "        - <h4> Modelamiento Nro 2 </h4>\n",
    "            - <h5>Linear Regresion (Regesión lineal / regresión logística)</h5>\n",
    "                - Entrenamiento\n",
    "                    - Matriz de confusión\n",
    "                - Prueba\n",
    "                    - Matriz de confusión\n",
    "            - <h5>Knn (K-Nearest Neighbors)</h5>\n",
    "                - Entrenamiento\n",
    "                    - Matriz de confusión\n",
    "                - Prueba\n",
    "                    - Matriz de confusión\n",
    "            - <h5>Decision tree (Árbol de decisión)</h5>\n",
    "                - Entrenamiento\n",
    "                    - Matriz de confusión\n",
    "                - Prueba\n",
    "                    - Matriz de confusión\n",
    "            - <h5>SVM - Support vector machine (Máquinas de vectores de soporte)</h5>\n",
    "                - Entrenamiento\n",
    "                    - Matriz de confusión\n",
    "                - Prueba\n",
    "                    - Matriz de confusión\n",
    "        - <h4> Segundas conclusiones </h4>\n",
    "- <h2> Análisis final por matriz de conclusiones </h2>\n",
    "    - <h4>Recomendaciones</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Definición del problema real\n",
    "====\n",
    "Los datos están relacionados con las campañas de marketing directo de una institución bancaria portuguesa. Las campañas de marketing se basaron en llamadas telefónicas. A menudo, se requirió más de un contacto para el mismo cliente, para conocer si el producto (depósito a plazo bancario) estaría suscrito ('sí') o no ('no').\n",
    "\n",
    "<h2>Objetivo</h2>\n",
    "\n",
    "El objetivo de la clasificación es predecir si el cliente suscribirá (sí / no) un depósito a plazo (variable y).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Información de atributos\n",
    "\n",
    "## Variables de entrada:\n",
    "\n",
    "### Datos del cliente:\n",
    "1. Age: edad, (numérico)\n",
    "2. job : trabajo,  tipo de trabajo (categórico: 'admin.', 'Trabajador', 'empresario', 'empleada doméstica', 'gerente', 'jubilado', 'autónomo', 'servicios', 'estudiante' , 'técnico', 'desempleado', 'desconocido')\n",
    "3. marital: estado civil (categórico: \"divorciado\", \"casado\", \"soltero\", \"desconocido\"; nota: \"divorciado\" significa divorciado o viudo)\n",
    "4. education : educación (categórica: 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'analfabeto', 'professional.course', 'university.degree', 'unknown')\n",
    "5. default; predeterminado, ¿tiene crédito en defecto? (categórico: 'no', 'sí', 'unknown')\n",
    "6. housing: vivienda, ¿tiene préstamo de vivienda? (categórico: 'no', 'sí', 'unknown')\n",
    "7. loan: préstamo, tiene préstamo personal? (categórico: 'no', 'sí', 'unknown')\n",
    "\n",
    "#### relacionado con el último contacto de la campaña actual:\n",
    "\n",
    "8. contact: contacto, tipo de comunicación de contacto (categórico: 'celular', 'teléfono')\n",
    "9. month: mes, último mes del año del contacto (categórico: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10. day_of_week: día de la semana,  último día de contacto de la semana (categórico: 'mon', 'tue', 'wed', 'thu', 'fri')\n",
    "11. duration: duración, duración del último contacto, en segundos (numérico). \n",
    "\n",
    "*** Nota importante: *** este atributo afecta en gran medida al objetivo de salida (por ejemplo, si la duración = 0, entonces y = 'no'). Sin embargo, la duración no se conoce antes de que se realice una llamada. Además, después del final de la llamada y es obviamente conocido. Por lo tanto, esta información solo debe incluirse para fines de referencia y debe descartarse si la intención es tener un modelo predictivo realista.\n",
    "\n",
    "#### otros atributos:\n",
    "12. campaign: campaña, número de contactos realizados durante esta campaña y para este cliente (numérico, incluye el último contacto)\n",
    "13. pdays: días, número de días que pasaron después de que el cliente fue contactado por última vez de una campaña anterior (numérico; 999 significa que el cliente no fue contactado previamente)\n",
    "14. previous: anterior, número de contactos realizados antes de esta campaña y para este cliente (numérico)\n",
    "15. poutcome: resultado de la campaña de marketing anterior (categórica: 'fracaso', 'inexistente', 'éxito')\n",
    "\n",
    "#### atributos del contexto social y económico\n",
    "16. emp.var.rate: tasa de variación del empleo - indicador trimestral (numérico)\n",
    "17. cons.price.idx: índice de precios al consumidor - indicador mensual (numérico)\n",
    "18. cons.conf.idx: índice de confianza del consumidor - indicador mensual (numérico)\n",
    "19. euribor3m: euribor tasa de 3 meses - indicador diario (numérico)\n",
    "20. nr.employed: número de empleados - indicador trimestral (numérico)\n",
    "\n",
    "#### Variable de salida (objetivo deseado):\n",
    "21. y: ¿El cliente ha suscrito un depósito a plazo? (binario: 'sí', 'no')  \n",
    "*** Nota: *** se va a usar la variable \"y\" para realizar los grupos de clasificación\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición y carga de las librerias\n",
    "from random import sample\n",
    "import os\n",
    "import ipyparallel as ipp\n",
    "rc = ipp.Client()\n",
    "ar = rc[:].apply_async(os.getpid)\n",
    "pid_map = ar.get_dict()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "# from scipy.stats import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_row', 1000)                         \n",
    "pd.set_option('display.max_columns', 50) \n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorizar\n",
    "def factor(dataset,full=0):\n",
    "    enc = LabelEncoder()\n",
    "    labels=dataset._get_numeric_data().columns\n",
    "    for n in range(len(dataset.columns)):\n",
    "        if df.columns[n] not in labels:\n",
    "            dataset[dataset.columns[n]] = enc.fit_transform(dataset[dataset.columns[n]])\n",
    "        if full== 1:\n",
    "            dataset[dataset.columns[n]] = enc.fit_transform(dataset[dataset.columns[n]])\n",
    "    return(dataset)\n",
    "\n",
    "# Función para buscar valores y remplazar por otros, se hace para cambiar a nulos valores como los uknonw\n",
    "def nulos(dataset, valini=\"\",valfin=\"\"):\n",
    "    new=dataset.copy()\n",
    "    for n in range(len(dataset.columns)):\n",
    "        if valfin == \"Nulos\":\n",
    "            new[dataset.columns[n]]=dataset[dataset.columns[n]].replace([valini],np.NaN)\n",
    "        else:\n",
    "            new[dataset.columns[n]]=dataset[dataset.columns[n]].replace([valini],valfin)\n",
    "    return(new)\n",
    "\n",
    "# Función para describir los tipos de datos de un dataset\n",
    "def data_description_ltype(dataset): \n",
    "    ds=dataset.dtypes\n",
    "    ds=pd.DataFrame(ds)\n",
    "    ds=ds.reset_index()\n",
    "    ds.columns=['variables','tipos']\n",
    "    return(ds)\n",
    "\n",
    "# Función que captura las etiquetas de un dataset y las devuelve en un nuevo dataframe\n",
    "def get_labels(dataset,objetive=''):\n",
    "    target = dataset.loc[:,[objetive]].values\n",
    "    labels_target=pd.DataFrame(dataset.loc[:,[objetive]].columns, columns=['target'])\n",
    "    labels=pd.DataFrame(dataset.columns, columns=['full'])\n",
    "    labels=labels[labels['full']!= objetive]\n",
    "    labels_num=dataset._get_numeric_data().columns\n",
    "    labels_text=pd.DataFrame(dataset.drop(labels_num[0],axis=1, inplace=False).columns[:-1], columns=['text'])\n",
    "    labels_num=pd.DataFrame(labels_num, columns=['num'])\n",
    "    l= pd.concat([labels,labels_text,labels_num, labels_target], axis=1)\n",
    "    return(l)\n",
    "\n",
    "# Función para realizar el balanceo de la información\n",
    "def balanceo(data,objetivo='',tam_muestra=80):\n",
    "    if objetivo=='':\n",
    "        return(print('ingrese la variable objetivo para dividir el tamaño de la muestra'))\n",
    "    df_y_yes=(data[data[objetivo]==1.0].reset_index()).drop('index', axis=1)\n",
    "    df_y_no=(data[data[objetivo]==0.0].reset_index()).drop('index', axis=1)\n",
    "    N=((data[objetivo][data[objetivo]==1].count()*tam_muestra)/100).astype(int)\n",
    "    rows_y=list(range(0, len(df_y_yes)))\n",
    "    rows_n=list(range(0, len(df_y_no)))\n",
    "    ran_row_y=sample(rows_y,k=N)\n",
    "    ran_row_n=sample(rows_n,k=N)\n",
    "    finalDf_train=pd.concat([pd.DataFrame(df_y_yes, index=ran_row_y), pd.DataFrame(df_y_no, index=ran_row_n)])\n",
    "    finalDf_train=finalDf_train.sort_index()\n",
    "    finalDf_test=pd.concat([df_y_yes.drop(df_y_yes.index[ran_row_y], inplace=False), df_y_no.drop(df_y_no.index[ran_row_y], inplace=False)])\n",
    "    finalDf_test=finalDf_test.sort_index().reset_index().drop('index', axis=1)\n",
    "    return(finalDf_train, finalDf_test)\n",
    "\n",
    "# Función para filtrar datos no nulos\n",
    "def limpiar_labels(label,columna):\n",
    "    l=pd.DataFrame(label[columna])\n",
    "    l=nulos(l,np.NaN,'unknwon')\n",
    "    l=l[columna][l[columna] != 'unknwon']\n",
    "    return(l)\n",
    "\n",
    "# Funciones de graficación-------------------------------\n",
    "\n",
    "#Estilo correlación\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"8pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "\n",
    "# Mapa de correlación\n",
    "def correl(correlacion):\n",
    "    cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
    "    return (correlacion.style.background_gradient(cmap, axis=1)\\\n",
    "        .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "        .set_caption(\"Matriz de correlación\")\\\n",
    "        .set_precision(2)\\\n",
    "        .set_table_styles(magnify()))\n",
    "\n",
    "# Gráficas verticales\n",
    "def grafica_ver(data,columna='', titulo='Gráfica',yetiqueta=''):\n",
    "    if columna == '':\n",
    "        return(print('ingrese parametros'))\n",
    "    ax = data[columna].value_counts().plot(kind='bar', figsize=(10,5), color=\"coral\", fontsize=13);\n",
    "    ax.set_alpha(0.2)\n",
    "    ax.set_title(titulo, fontsize=12)\n",
    "    ax.set_ylabel(yetiqueta, fontsize=12);\n",
    "    ax.set_yticks([0, len(data)+1000])\n",
    "    totals = []\n",
    "    for i in ax.patches:\n",
    "        totals.append(i.get_height())\n",
    "    total = sum(totals)\n",
    "    for i in ax.patches:\n",
    "        ax.text(i.get_x()+.12, i.get_height()-3, \\\n",
    "                str(i.get_height())+'\\n('+str(round((i.get_height()/len(data))*100, 2))+'%)', fontsize=12,\n",
    "                    color='dimgrey')\n",
    "\n",
    "# Gráficas horizontales\n",
    "def grafica_hor(data,columna='', titulo='Gráfica',xetiqueta='x'):\n",
    "    if columna == '':\n",
    "        return(print('ingrese parametros'))\n",
    "    \n",
    "    ax =data[columna].value_counts().plot(kind='barh', figsize=(10,5), color=\"teal\", fontsize=13);\n",
    "    ax.set_alpha(0.2)\n",
    "    ax.set_title(titulo, fontsize=12)\n",
    "    ax.set_xlabel(xetiqueta, fontsize=12);\n",
    "    ax.set_xticks([0, len(data)])\n",
    "    totals = []                                          # create a list to collect the plt.patches data\n",
    "    for i in ax.patches:                                 # find the values and append to list\n",
    "        totals.append(i.get_width())\n",
    "    total = sum(totals)                                  # set individual bar lables using above list\n",
    "    for i in ax.patches:                                 \n",
    "        ax.text(i.get_width()+.3, i.get_y()+.38, \\\n",
    "                str(i.get_width())+' ('+str(round((i.get_width()/len(data))*100, 2))+'%)', fontsize=12, color='dimgrey')\n",
    "    return(ax.invert_yaxis())                            # invert for largest on top \n",
    "\n",
    "# Gráficas de nulos\n",
    "def grafica_nul(data):\n",
    "    df_limpiar=data.copy()\n",
    "    df_limpiar= nulos(df_limpiar,'unknown','Nulos')\n",
    "    df_limpiar= nulos(df_limpiar,999,'Nulos')\n",
    "    df_limpiar=pd.DataFrame(df_limpiar.isnull().sum(), columns=['nulos'])\n",
    "    df_limpiar = df_limpiar[df_limpiar.nulos != 0]\n",
    "    df_limpiar=df_limpiar.sort_values('nulos', ascending=False)\n",
    "    ax =df_limpiar['nulos'].plot(kind='barh', figsize=(10,5), color=\"salmon\", fontsize=13);\n",
    "    ax.set_alpha(0.2)\n",
    "    ax.set_title('Datos Nulos', fontsize=12)\n",
    "    ax.set_xlabel('Cantidad', fontsize=12);\n",
    "    ax.set_xticks([0, len(data)])\n",
    "    totals = []                                          \n",
    "    for i in ax.patches:                                 \n",
    "        totals.append(i.get_width())\n",
    "    total = sum(totals)                                 \n",
    "    for i in ax.patches:                                 \n",
    "        ax.text(i.get_width()+.3, i.get_y()+.38, \\\n",
    "                str(i.get_width())+' ('+str(round((i.get_width()/len(data))*100, 2))+'%)', fontsize=12, color='red')\n",
    "    return(ax.invert_yaxis())\n",
    "\n",
    "# Gráficas de puntuaciones de los clasificadores\n",
    "def grafica_scores(modelo, x_test, y_test, y_pred): \n",
    "    print(\"Score:\",modelo.score(x_test,y_test))\n",
    "    print(\"accuracy_score:\",accuracy_score(y_true = y_test, y_pred = y_pred))\n",
    "    print(\"Tasa de error:\",1-accuracy_score(y_true = y_test, y_pred = y_pred))\n",
    "    print(\"jaccard_similarity_score\",jaccard_similarity_score(y_true=y_test, y_pred=y_pred))\n",
    "    print(print(\"\\n\\nclassification_report\\n---------------------\\n\",classification_report(y_true=y_test, y_pred=y_pred)))\n",
    "\n",
    "# Gráfica de matriz de confusión\n",
    "def grafica_matriz_confusion(modelo, ax='', titulo=''):\n",
    "    if ax=='':\n",
    "        ax= plt.subplot();\n",
    "    sns.heatmap(modelo, annot=True, ax = ax,square=True, cmap=\"YlGnBu\", annot_kws={\"size\":12}, fmt=\"d\");\n",
    "    ax.set_xlabel('Predicción\\n' , fontsize='16');\n",
    "    ax.set_ylabel('Verdaderos\\n' , fontsize='16'); \n",
    "    ax.set_title('Matriz de confusión '+titulo+'\\n', fontsize='18'); \n",
    "    ax.xaxis.set_ticklabels(['no', 'yes'], fontsize='16'); \n",
    "    ax.yaxis.set_ticklabels(['no', 'yes'], fontsize='16');\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fase de exploración y limpieza de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank_af.csv', delimiter=\";\")\n",
    "df_limpiar = df.copy()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio Nro. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observan variables de diferentes tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_var=len(df.columns)\n",
    "num_var=len(df._get_numeric_data().columns)\n",
    "print(df.dtypes, \"\\n\\nTotal de variables\", tot_var, \"\\nNuméricas\", num_var, \"\\nObjetos\", tot_var-num_var, \"\\nTotal de registros\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se hace descripción de los datos actuales y se observan desviaciones altas en algunas de las variables.\n",
    "* De las 22 variables, incialmente se pueden describir solamente 10 que son las numéricas(cuantitativas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se aplican conversiones de los datos tipo objeto a tipo numéricos, respetando los datos númericos de las demás variables y se verifican nuevamente los tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=factor(df)\n",
    "tot_var=len(df.columns)\n",
    "num_var=len(df._get_numeric_data().columns)\n",
    "print(df.dtypes, \"\\n\\nTotal de variables\", tot_var, \"\\nNuméricas\", num_var, \"\\nObjetos\", tot_var-num_var, \"\\nTotal de registros\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observan nuevamente los datos se observan desviaciones altas en algunas de las variables.\n",
    "* Ya se pueden observar las 22 variables del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hacemos una exploración visual de la información usando gráficos de densidad\n",
    "* Se obseva que la información esta en diferentes escalas, por lo cual se debe aplicar un metodo de escalado más adelante para poder entrenar y probar los diferentes modelos seleccionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='density', subplots=True, layout=(17,3), sharex=False, figsize=(15,35))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los datos contienen información que debe ser depurada. Dentro del set de datos contiene valores \"unknown\" y \"999\" que no son validos para el análisis ya que no están asociados a los valores reales que se pueden encontrar dentro de la variable. Para esto se debe decidir si se completan los datos o se omiten para la exploración y creación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.isnull().sum(), columns=['Conteo']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como se hizo una transformación, los datos \"Unknwon\" fueron vueltos numeros y se representaron como un número, pero para esta exploración es importante que cantidad de nulos existen; por esto se debe hacer una limpieza de estos valores anter de volverlos factor.  \n",
    "\n",
    "* Se observa que existe una variable (pdays, education) que no aporta valor para el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpiar= nulos(df_limpiar,'unknown','Nulos')\n",
    "df_limpiar= nulos(df_limpiar,999,'Nulos')\n",
    "print(\"Nulos\")\n",
    "pd.DataFrame(df_limpiar.isnull().sum(), columns=['Conteo']).transpose()\n",
    "print(\"\\nNo nulos\")\n",
    "pd.DataFrame(df_limpiar.count(), columns=['Conteo']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los datos quedan de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpiar=df_limpiar.drop(['pdays','education', 'duration'], axis=1)\n",
    "print(\"Nulos\")\n",
    "pd.DataFrame(df_limpiar.isnull().sum(),columns=['Conteo']).transpose()\n",
    "print(\"\\nNo nulos\")\n",
    "pd.DataFrame(df_limpiar.count(), columns=['Conteo']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para los demás datos se aplican factores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpiar= nulos(df_limpiar,np.NaN,'unknwon')\n",
    "df_limpiar=factor(df_limpiar,1)\n",
    "df_limpiar.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se mira la distribución de la información en las variables, con la factorización aplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpiar.plot(kind='density', subplots=True, layout=(17,3), sharex=False, figsize=(15,35))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veo que tan dispersos están los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpiar.plot(kind='box', subplots=True, layout=(17,3), sharex=False, sharey=False, figsize=(15,40))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observamos la matriz de correlación para ver entre variables el comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_limpiar.corr()\n",
    "correl(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* De la matriz de correlación se puede observar que hay otras variables que no aportan valor para el análisis, se escogen una de las fuertemente correlacionadas y se eliminan: euribor3m, nr.employed, cons.conf.idx, cons.price.idx; además en la explicación del tipo de variables se nota que esta información de las variables generan ruido con respecto a las varibles propias de la campaña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpiar=df_limpiar.drop(['euribor3m','nr.employed', 'cons.conf.idx','cons.price.idx'], axis=1)\n",
    "correlations = df_limpiar.corr()\n",
    "correl(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se aplica escalado a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = df_limpiar.columns[:-1]\n",
    "datos = df_limpiar.loc[:, variables].values\n",
    "target = df_limpiar.loc[:,['y']].values\n",
    "scaler = MinMaxScaler()\n",
    "datos = scaler.fit_transform(datos)\n",
    "pd.DataFrame(datos).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se revisa que tan distribuidos están los datos después de aplicar el escalado. Se quiere observar que se mantenga la proporción de la información después de esta técnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_escalados=pd.DataFrame(datos, columns=variables)\n",
    "datos_escalados.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = datos_escalados.corr()\n",
    "correl(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se obtienen componentes principales por medio de la técnica de PCA, los cuales se usarán para demostrar que pasa si se aplican al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=13)\n",
    "principalComponents = pca.fit_transform(datos_escalados)\n",
    "principalComponents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(principalComponents).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Proporción explicada de varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.explained_variance_ratio_).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La gráfica indica que con 9 componentes que se apliquen a modelo podemos obtener aprox el 100% del análisis de la información; si ya se aplican más componentes, estos no me generarán valor al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('número de componentes')\n",
    "plt.ylabel('varianza explicada acumulativa');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=9)\n",
    "principalComponents = pca.fit_transform(datos_escalados)\n",
    "principalComponents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se completa el dataset para aplicar al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "finalDf = pd.concat([principalDf, df_limpiar[['y']]], axis = 1)\n",
    "finalDf.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validamos la correlación nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = finalDf.corr()\n",
    "correl(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer instancia se va a aplicar la información del análisis por componentes (PCA) y observar que pasa con el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se divide el dataset en partes de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( finalDf,target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **** Regresión logística **** \n",
    "\n",
    "Se aplica el solver **lbfgs** el cual es mucho más eficiente y veloz\n",
    "\n",
    "* Evaluamos la precisión del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'lbfgs', max_iter=100);\n",
    "lr.fit(x_train, y_train);\n",
    "y_pred = lr.predict(x_test);\n",
    "pd.DataFrame(y_pred).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Primera conclusión\n",
    "\n",
    "* Se observa que el modelo está respondiendo en un 100% con la información que se le envía, por lo cual es mejor replantear el uso de los datos, ya que al aplicar esta técnica se hace un sobre entrenamiento del modelo.\n",
    "* Los componentes generados por esta téncnica no deben aplicarse al modelo ya que esto no es adecuado y la información va a presentar un sobrentrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score:\",lr.score(x_test,y_test))\n",
    "print(\"accuracy_score:\",accuracy_score(y_true = y_test, y_pred = y_pred))\n",
    "print(\"jaccard_similarity_score\",jaccard_similarity_score(y_true=y_test, y_pred=y_pred))\n",
    "print(print(\"\\n\\nclassification_report\\n---------------------\\n\",classification_report(y_true=y_test, y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creamos y graficamos la matriz de confusión, la cual nos confirma una vez más que algo anda mal con el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm = confusion_matrix(y_test, y_pred)\n",
    "print('\\n')\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(lr_cm, annot=True, ax = ax,square=True, cmap=\"YlGnBu\", annot_kws={\"size\":12}, fmt=\"d\");\n",
    "ax.set_xlabel('Predicción' , fontsize='16');\n",
    "ax.set_ylabel('Verdaderos' , fontsize='16'); \n",
    "ax.set_title('Matriz de confusión', fontsize='18'); \n",
    "ax.xaxis.set_ticklabels(['no', 'yes'], fontsize='16'); \n",
    "ax.yaxis.set_ticklabels(['no', 'yes'], fontsize='16');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_y=pd.Categorical(finalDf.y)\n",
    "c=category_y.describe()\n",
    "c=c.reset_index()\n",
    "c.categories=c.categories.replace([0],'No')\n",
    "c.categories=c.categories.replace([1],'Yes')\n",
    "c.plot(x='categories', y='freqs', kind=\"bar\", legend =False)\n",
    "plt.ylabel(\"freqs\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validamos el target para serciorarnos el % de la precisión mostrada en el modelo\n",
    "* Se observa un peso elevado en una de las categorias del target y con las observaciones anteriores de media, se ven que están claramente definidos los grupos de las clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio Nro 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se va a realizar nuevamente la importación de la información para evitar usar dataset que ya se hayan cargado antes.  \n",
    "\n",
    "** Importación de los datos **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Revisión de tipos de datos en el dataset: Se grafican los tipos de datos existentes en el dataset, esto va a permitir tomar decisiones para el tratamiento del mismo (busqueda de variables categoricas).\n",
    "* Revisión de nulos en el dataset: Es importante conocer la cantidad de información que pueda existir faltante en el dataset.\n",
    "* Balanceo de la información en el dataset: Muestra el estado actual de la variable objetivo, mostrando si esta o no desbalanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan los datos nuevamente\n",
    "df = pd.read_csv('bank_af.csv', delimiter=\";\")\n",
    "df=df.drop(['duration'], axis=1)\n",
    "\n",
    "# Revisión de tipos de datos en el dataset\n",
    "grafica_hor(data_description_ltype(df),'tipos', 'Tipo de información existente','Existencia');\n",
    "\n",
    "# Revisión de nulos en el dataset\n",
    "plt.subplots(1, 1)\n",
    "grafica_nul(df);\n",
    "\n",
    "# Balanceo de la información en el dataset\n",
    "plt.subplots(1, 1)\n",
    "grafica_ver(df,'y','Proporción del Objetivo', '% en el dataframe');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eliminación de variable que no aporta valor para el modelo: en este caso se revisa que la variable pdays tiene el 96% de la información con valores nulos (aprox), por lo cual no aporta valor al modelo.\n",
    "* Luego de esto se grafica y se observa que las variables que quedan, tienen un bajo contenido de información nula, las cuales se pueden tratar por medio de imputaciones o simplemente se asigna una categoria (unknown); se opta por la segunda opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de variable que no aporta valor para el modelo\n",
    "df=df.drop('pdays',axis=1)\n",
    "grafica_nul(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El siguiente paso exploratorio es hacer una comparación de cada una de las variables con respecto al objetivo; la idea con esto es que por medio de una exploración visual se identifquen frecuencias que permitan tomar decisiones más claras al momento de aplicar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_labels=df.columns[:-1];\n",
    "for i in range(len(df_labels)):\n",
    "    f, ax = plt.subplots(figsize=(17,5));\n",
    "    sns.countplot(x=df_labels[i], hue=\"y\", data=df, ax=ax, palette=\"ocean_r\");\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La variable education es una variable categorica con jerarquia, como se conoce su jerarquia, se hace una conversión de factor manualmente respetando la jerarquia que se presenta entre los contenidos de esta variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education=pd.DataFrame(df.groupby('education').size()).reset_index()\n",
    "education.columns=['education','Conteo']\n",
    "education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.education=df['education'].replace(['unknown','illiterate','basic.4y','basic.6y','basic.9y','high.school','professional.course','university.degree']\n",
    "                                    ,['0','1','2','3','4','5','6','7'])\n",
    "df.education=pd.to_numeric(df['education'])\n",
    "pd.DataFrame(pd.DataFrame(df.education.values, columns=['education']).groupby('education').size(), \n",
    "             columns=['Conteo']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ya plenamente identificadas las variables y aplicadas las transformaciones necesarias, se va a usar la técnica de imputación de dummies para las variables tipo categoricas, ya que no podemos determinar si existe jerarquia entre ellas; a excepción de nuestro objetivo que se puede volver tipo factor para darle valores que en este caso se comportará como si fuese un binario (1, 0), para las demas variables categoricas se aplica la técnica antes dicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = factor(pd.DataFrame(df.loc[:,['y']].values, columns=['target']))\n",
    "labels_data=get_labels(df,'y')\n",
    "labels_t=limpiar_labels(labels_data, 'text')\n",
    "labels_n=limpiar_labels(labels_data, 'num')\n",
    "df_dummy = pd.get_dummies(df[labels_t])\n",
    "df_final=pd.concat([df[labels_n],df_dummy, target], axis=1)\n",
    "labels_dummy=df_final.columns\n",
    "print('\\nNueva descripción de la información transformada a tipo dummies\\n')\n",
    "df_final.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aplicamos matriz de correlacion entre variables, en las cuales los colores azules indican una alta correlación entre las variablas (no significa que exista una fuerte relación entre estas, para ello se debería hacer prueba de hipotesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df.corr()\n",
    "correl(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para que la información quede en una misma escala para el análisis, se le debe aplicar alguna técnica que permita llevarla a unos rangos entre 0 y 1; se elige la técnica de MinMax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "datos = scaler.fit_transform(df_final)\n",
    "datos=pd.DataFrame(datos, columns=[labels_dummy])\n",
    "print('\\nNuevo escalamiento de la información\\n')\n",
    "datos.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Revisamos que despúes del escalado la información siga teniendo la misma distribución, para esto graficamos y usamos gráficas de bigotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.plot(kind='box', subplots=True, layout=(63,3), sharex=False, sharey=False, figsize=(15,300))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observamos la proporción de la información de nuestro objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafica_ver(df_final,'target','Proporción del Objetivo antes del balanceo', '% en el dataframe');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una vez analizado el dataset se opta por realizar un balanceo, que consiste en tomar una parte aleatoria del dataset completo, teniendo como referencia la variable objetivo con menor cantidad de datos existentes; luego de esto, se construyen 2 dataset nuevos, uno para el entrenamiento que es la parte balanceada y la parte excedente se usará para la  prueba de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf_train, finalDf_test=balanceo(df_final,objetivo='target',tam_muestra=80)\n",
    "grafica_ver(finalDf_train,'target','Proporción del Objetivo balanceado entrenamiento', '% en el dataframe');\n",
    "plt.subplots(1, 1);\n",
    "grafica_ver(finalDf_test,'target','Proporción del balanceado Objetivo prueba (excedente del dataset)'\n",
    "            , '% en el dataframe');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Revisamos que no nos afecte el comportamiento original de la información para que el modelo no reciba información sesgada o incompleta; para esto usamos una gráfica de densidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.plot(kind='density', subplots=True, layout=(64,3), sharex=False, figsize=(15,300));\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Revisamos con gráfica de bigotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final[labels_dummy].plot(kind='box', subplots=True, layout=(64,3), sharex=False, sharey=False, figsize=(15,300));\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graficamos la matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlations=df_final.corr(method = 'pearson')\n",
    "f, ax = plt.subplots(figsize=(15, 15));\n",
    "cmap=sns.light_palette(\"navy\", reverse=True, as_cmap=True);\n",
    "sns.heatmap(correlations, fmt=\"d\",ax=ax, cmap=cmap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Modelamiento Nro 2\n",
    "\n",
    "Una vez se tienen listos los datos, es hora de aplicarlos a nuestros modelos.\n",
    "\n",
    "- <h4> Linear Regresion (Regesión lineal / regresión logística) </h4>\n",
    "    - <h5>Entrenamiento</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = finalDf_train.loc[:,['target']].values\n",
    "x_tr = finalDf_train.drop('target', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tr,target_train, test_size=0.2)\n",
    "lr = LogisticRegression(solver = 'lbfgs', max_iter=1000000);\n",
    "lr.fit(x_train, y_train);\n",
    "print('Estadísticas de precisión\\n')\n",
    "y_pred = lr.predict(x_test)\n",
    "grafica_scores(lr, x_test, y_test, y_pred);\n",
    "lr_cm = confusion_matrix(y_test, y_pred);\n",
    "grafica_matriz_confusion(lr_cm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con la aplicación de esta técnica, se ve un resultado más real al observado en la primera observación.\n",
    "    - <h5>Prueba</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_true=finalDf_test.loc[:,['target']].values\n",
    "x_tr_true=finalDf_test.drop('target', axis=1);\n",
    "x_train_true, x_test_true, y_train_true, y_test_true = train_test_split(x_tr_true,target_true, test_size=0.8);\n",
    "print('Estadísticas de precisión\\n')\n",
    "y_test_pred_true=lr.predict(x_test_true);\n",
    "grafica_scores(lr, x_test_true, y_test_true, y_test_pred_true);\n",
    "lr_cm_true = confusion_matrix(y_test_true, y_test_pred_true);\n",
    "grafica_matriz_confusion(lr_cm_true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa una mayor precisión en el modelo cuando se aplican los datos de prueba. Obteniendose como resultado un mejor modelo comparado con el primero utilizado.\n",
    "\n",
    "Se aplica un segundo tipo de modelado:\n",
    "\n",
    "- <h4> Knn (K-Nearest Neighbors) </h4>\n",
    "    - <h5>Entrenamiento</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_train = finalDf_train.loc[:,['target']].values\n",
    "x_tr = finalDf_train.drop('target', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tr,target_train, test_size=0.2)\n",
    "knn = KNeighborsClassifier(n_neighbors=21);\n",
    "print('Estadísticas de precisión\\n')\n",
    "knn.fit(x_train, y_train);\n",
    "y_pred = knn.predict(x_test);\n",
    "grafica_scores(knn, x_test, y_test, y_pred);\n",
    "knn_cm = confusion_matrix(y_test, y_pred);\n",
    "grafica_matriz_confusion(knn_cm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con la aplicación de esta técnica, se observa un resultado similar al de la técnica de modelado anterior.  \n",
    "* Procedemos a hacer la prueba con los demás datos del dataset balanceado.\n",
    "    - <h5>Prueba</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_true=finalDf_test.loc[:,['target']].values\n",
    "x_tr_true=finalDf_test.drop('target', axis=1)\n",
    "x_train_true, x_test_true, y_train_true, y_test_true = train_test_split(x_tr_true,target_true, test_size=0.8);\n",
    "print('Estadísticas de precisión\\n')\n",
    "y_test_pred_true=knn.predict(x_test_true);\n",
    "grafica_scores(lr, x_test_true, y_test_true, y_test_pred_true);\n",
    "knn_cm_true = confusion_matrix(y_test_true, y_test_pred_true);\n",
    "grafica_matriz_confusion(knn_cm_true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa una mayor precisión en el modelo cuando se aplican los datos de prueba. Obteniendose como resultado un mejor modelo comparado con el primero utilizado.\n",
    "\n",
    "Se aplica un tercer tipo de modelado:\n",
    "\n",
    "- <h4> Decision tree (Arbol de decisión) </h4>\n",
    "    - <h5>Entrenamiento</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = finalDf_train.loc[:,['target']].values\n",
    "x_tr = finalDf_train.drop('target', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tr,target_train, test_size=0.2)\n",
    "clf = DecisionTreeClassifier(max_depth=2);\n",
    "print('Estadísticas de precisión\\n')\n",
    "clf.fit(x_train, y_train);\n",
    "y_test_pred = clf.predict(x_test);\n",
    "clf_cm=confusion_matrix(y_test, y_test_pred);\n",
    "grafica_scores(clf, x_test, y_test, y_test_pred);\n",
    "grafica_matriz_confusion(clf_cm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con la aplicación de esta técnica, se observa un resultado similar al de la técnica de modelado anterior.  \n",
    "* Procedemos a hacer la prueba con los demás datos del dataset balanceado.\n",
    "    - <h5>Prueba</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_true=finalDf_test.loc[:,['target']].values\n",
    "x_tr_true=finalDf_test.drop('target', axis=1)\n",
    "x_train_true, x_test_true, y_train_true, y_test_true = train_test_split(x_tr_true,target_true, test_size=0.8)\n",
    "y_test_pred_true=clf.predict(x_test_true);\n",
    "print('Estadísticas de precisión\\n')\n",
    "grafica_scores(clf, x_test_true, y_test_true, y_test_pred_true);\n",
    "clf_cm_true = confusion_matrix(y_test_true, y_test_pred_true);\n",
    "grafica_matriz_confusion(clf_cm_true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa una mayor precisión en el modelo cuando se aplican los datos de prueba. Obteniendose como resultado un mejor modelo comparado con el primero utilizado.\n",
    "\n",
    "Se aplica un cuarto tipo de modelado:\n",
    "\n",
    "- <h4> SVM - Support vector machine (Máquinas de vectores de soporte) </h4>\n",
    "    - <h5>Entrenamiento</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = finalDf_train.loc[:,['target']].values\n",
    "x_tr = finalDf_train.drop('target', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tr,target_train, test_size=0.2)\n",
    "svm = SVC(kernel='linear');\n",
    "print('Estadísticas de precisión\\n')\n",
    "svm.fit(x_train, y_train);\n",
    "y_test_pred = svm.predict(x_test);\n",
    "svm_cm=confusion_matrix(y_test, y_test_pred);\n",
    "grafica_scores(svm, x_test, y_test, y_test_pred);\n",
    "grafica_matriz_confusion(svm_cm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm.support_vectors_).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con la aplicación de esta técnica, se observa un resultado similar al de la técnica de modelado anterior.  \n",
    "* Procedemos a hacer la prueba con los demás datos del dataset balanceado.\n",
    "    - <h5>Prueba</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_true=finalDf_test.loc[:,['target']].values\n",
    "x_tr_true=finalDf_test.drop('target', axis=1)\n",
    "x_train_true, x_test_true, y_train_true, y_test_true = train_test_split(x_tr_true,target_true, test_size=0.8)\n",
    "y_test_pred_true=svm.predict(x_test_true);\n",
    "print('Estadísticas de precisión\\n')\n",
    "grafica_scores(svm, x_test_true, y_test_true, y_test_pred_true);\n",
    "svm_cm_true = confusion_matrix(y_test_true, y_test_pred_true);\n",
    "grafica_matriz_confusion(svm_cm_true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa una mayor precisión en el modelo cuando se aplican los datos de prueba. Obteniendose como resultado un mejor modelo comparado con el primero utilizado.\n",
    "\n",
    "---\n",
    "#### Segunda conclusión\n",
    "\n",
    "* Aplicando una preparación previa a los datos, revisando que contiene, limpiandola pero sobre todo entendiendo el set de datos que se tiene, se logra un mejor trabajo con la aplicación de los modelos usados\n",
    "* En cada uno de los modelos cuando se aplican los set de datos balanceados, se logra observar una respuesta similar, teniendo una variación muy baja entre cada uno de ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Análisis final por matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con los datos de entrenamiento\n",
    "\n",
    "<p style={color:\"green\"}> Sobre los datos de entrenamiento se observa que entre la predicción de los datos reales, se mantiene la proporción de en la exacitud de cada uno de los modelos aplicados </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "plt.figure(1, figsize=(12, 13));\n",
    "plt.subplots_adjust(left=0.05, right=0.95);\n",
    "ax = plt.subplot(221);\n",
    "grafica_matriz_confusion(lr_cm, ax, 'Regresión lineal');\n",
    "ax = plt.subplot(222);\n",
    "grafica_matriz_confusion(knn_cm, ax, 'Knn');\n",
    "ax = plt.subplot(223);\n",
    "grafica_matriz_confusion(clf_cm, ax, 'Arboles de decisión');\n",
    "ax = plt.subplot(224);\n",
    "grafica_matriz_confusion(svm_cm, ax, 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con los datos de prueba\n",
    "\n",
    "Se observa mayor precisión cuando se agregan los datos de prueba en cada uno de los modelos, esto nos permite analizar que cuando lleguen nuevos datos, el modelo será capaz de hacer un pronostico muy acertado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "plt.figure(1, figsize=(12, 13));\n",
    "plt.subplots_adjust(left=0.05, right=0.95);\n",
    "ax = plt.subplot(221);\n",
    "grafica_matriz_confusion(lr_cm_true, ax, 'Regresión lineal');\n",
    "ax = plt.subplot(222);\n",
    "grafica_matriz_confusion(knn_cm_true, ax, 'Knn');\n",
    "ax = plt.subplot(223);\n",
    "grafica_matriz_confusion(clf_cm_true, ax, 'Arboles de decisión');\n",
    "ax = plt.subplot(224);\n",
    "grafica_matriz_confusion(svm_cm_true, ax, 'SVM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recomendaciones\n",
    "\n",
    "* Para que los análisis sean más acertados se recomienda primero conocer el negocio y la necesidad que tiene este con respecto a la información, esto ayudará a tomar mejores decisiones a la hora de aplicar modelos.\n",
    "* Los modelos pueden tener comportamientos similares en su precisión para pronosticar, dependiendo esto de la cantidad de veces que se ejecute cada modelo y las configuraciones que se puedan aplicar a los mismos\n",
    "--- \n",
    "* De la informacion analizada, se puede observar un claro comportamiento con tendencia a respuestas negativas en caso usar sin transformar los datos.\n",
    "* Para este dataset puntualmente se tuvieron que aplicar técnicas de balanceo para que el modelo pudiera tener un mejor entrenamiento.\n",
    "* De acuerdo a los resultados de precisión, los modelos tendrían un grado de confianza del 80% aproximadamente con nuevos datos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
